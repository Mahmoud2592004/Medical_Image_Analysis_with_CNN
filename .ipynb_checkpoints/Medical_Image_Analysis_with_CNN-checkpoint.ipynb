{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0843a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, utils\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f81dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the images\n",
    "def load_and_preprocess(folder_path):\n",
    "    img_list = []\n",
    "    for path in os.listdir(path=folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, path))\n",
    "        img = cv2.resize(img,(250,250))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255 # Normalizing\n",
    "        img_list.append(img)\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d70707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class1 = load_and_preprocess(folder_path='chest_xray/train/NORMAL/')\n",
    "train_class2 = load_and_preprocess(folder_path='chest_xray/train/PNEUMONIA/')\n",
    "test_class1 = load_and_preprocess(folder_path='chest_xray/test/NORMAL/')\n",
    "test_class2 = load_and_preprocess(folder_path='chest_xray/test/PNEUMONIA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d25182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = train_class1 + train_class2\n",
    "test_list = test_class1 + test_class2\n",
    "train_labels = [0] * len(train_class1) + [1] * len(train_class2)\n",
    "test_labels = [0] * len(test_class1) + [1] * len(test_class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e945459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = np.array(train_list), np.array(test_list)\n",
    "y_train = utils.to_categorical(train_labels,num_classes=2)\n",
    "y_test = utils.to_categorical(test_labels,num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393e4a2",
   "metadata": {},
   "source": [
    "## Determine the best structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc9c5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a3f2c8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 104ms/step - accuracy: 0.6483 - loss: 2.5838 - val_accuracy: 0.8606 - val_loss: 0.4397\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 82ms/step - accuracy: 0.9230 - loss: 0.2766 - val_accuracy: 0.7772 - val_loss: 0.7193\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.8370 - loss: 0.3294 - val_accuracy: 0.8237 - val_loss: 0.7696\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 88ms/step - accuracy: 0.8748 - loss: 0.2792 - val_accuracy: 0.7837 - val_loss: 1.1620\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.8969 - loss: 0.2322 - val_accuracy: 0.8301 - val_loss: 0.6937\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.9179 - loss: 0.1963 - val_accuracy: 0.8221 - val_loss: 1.5527\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 88ms/step - accuracy: 0.8742 - loss: 0.2558 - val_accuracy: 0.7612 - val_loss: 1.2076\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.8878 - loss: 0.2358 - val_accuracy: 0.8157 - val_loss: 1.3254\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9348 - loss: 0.1609 - val_accuracy: 0.7676 - val_loss: 1.9398\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step - accuracy: 0.9460 - loss: 0.1310 - val_accuracy: 0.7917 - val_loss: 2.0861\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6408 - loss: 3.7408\n",
      "[2.0861034393310547, 0.7916666865348816]\n"
     ]
    }
   ],
   "source": [
    "# Structure 1:\n",
    "model = models.Sequential(\n",
    "[\n",
    "    layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "    layers.Conv2D(8,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "    layers.Conv2D(4,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_2'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_2'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=10, validation_data=(X_test,y_test))\n",
    "print(model.evaluate(x=X_test,y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6c40b1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 231ms/step - accuracy: 0.7233 - loss: 0.6112 - val_accuracy: 0.6250 - val_loss: 0.6919\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 107ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6912\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 100ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 98ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 105ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 97ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 107ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 93ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.2984 - loss: 1.0250\n",
      "[0.6908029913902283, 0.625]\n"
     ]
    }
   ],
   "source": [
    "# Structure 2:\n",
    "model = models.Sequential(\n",
    "[\n",
    "    layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "    layers.Conv2D(8,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=10, validation_data=(X_test,y_test))\n",
    "print(model.evaluate(x=X_test,y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4100267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 106ms/step - accuracy: 0.7258 - loss: 0.5560 - val_accuracy: 0.7179 - val_loss: 0.8038\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - accuracy: 0.8580 - loss: 0.2906 - val_accuracy: 0.7692 - val_loss: 1.2118\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 113ms/step - accuracy: 0.9070 - loss: 0.2095 - val_accuracy: 0.7484 - val_loss: 1.4164\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 104ms/step - accuracy: 0.9158 - loss: 0.1865 - val_accuracy: 0.7516 - val_loss: 1.8652\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 95ms/step - accuracy: 0.9355 - loss: 0.1393 - val_accuracy: 0.7308 - val_loss: 1.9363\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.9442 - loss: 0.1215 - val_accuracy: 0.7228 - val_loss: 2.4662\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 89ms/step - accuracy: 0.9441 - loss: 0.1287 - val_accuracy: 0.7548 - val_loss: 2.3793\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 94ms/step - accuracy: 0.9574 - loss: 0.1072 - val_accuracy: 0.7596 - val_loss: 2.7429\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 99ms/step - accuracy: 0.9622 - loss: 0.0878 - val_accuracy: 0.7500 - val_loss: 2.9895\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 95ms/step - accuracy: 0.9706 - loss: 0.0859 - val_accuracy: 0.7372 - val_loss: 3.0384\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5329 - loss: 5.2079\n",
      "[3.0384206771850586, 0.7371794581413269]\n"
     ]
    }
   ],
   "source": [
    "# Structure 3:\n",
    "model = models.Sequential(\n",
    "[\n",
    "    layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "    layers.Conv2D(8,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "    layers.Conv2D(4,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_2'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_2'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=10, validation_data=(X_test,y_test))\n",
    "print(model.evaluate(x=X_test,y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e7f6573c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 132ms/step - accuracy: 0.7537 - loss: 1.9188 - val_accuracy: 0.8333 - val_loss: 0.8390\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 96ms/step - accuracy: 0.9125 - loss: 0.2263 - val_accuracy: 0.7644 - val_loss: 0.8882\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 98ms/step - accuracy: 0.9205 - loss: 0.1825 - val_accuracy: 0.7356 - val_loss: 1.2278\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 103ms/step - accuracy: 0.9406 - loss: 0.1396 - val_accuracy: 0.7468 - val_loss: 1.5863\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 100ms/step - accuracy: 0.9712 - loss: 0.0833 - val_accuracy: 0.7340 - val_loss: 2.0995\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 123ms/step - accuracy: 0.9756 - loss: 0.0679 - val_accuracy: 0.7324 - val_loss: 2.3667\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 100ms/step - accuracy: 0.9785 - loss: 0.0512 - val_accuracy: 0.7196 - val_loss: 2.8922\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 114ms/step - accuracy: 0.9814 - loss: 0.0523 - val_accuracy: 0.7580 - val_loss: 2.7153\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 101ms/step - accuracy: 0.9820 - loss: 0.0496 - val_accuracy: 0.7500 - val_loss: 3.0045\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 98ms/step - accuracy: 0.9829 - loss: 0.0554 - val_accuracy: 0.7260 - val_loss: 3.4630\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5213 - loss: 5.6929\n",
      "[3.4629664421081543, 0.7259615659713745]\n"
     ]
    }
   ],
   "source": [
    "# Structure 4:\n",
    "model = models.Sequential(\n",
    "[\n",
    "    layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "    layers.Conv2D(8,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=10, validation_data=(X_test,y_test))\n",
    "print(model.evaluate(x=X_test,y=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f93fe0",
   "metadata": {},
   "source": [
    "###### Structure 1: [2.0861034393310547, 0.7916666865348816]\n",
    "###### Structure 2: [0.6908029913902283, 0.625]\n",
    "###### Structure 3: [3.0384206771850586, 0.7371794581413269]\n",
    "###### Structure 4: [3.4629664421081543, 0.7259615659713745]\n",
    "### So, structure 1 is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f7c7c",
   "metadata": {},
   "source": [
    "## Determine the best number of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2de168d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 435ms/step - accuracy: 0.6927 - loss: 0.6566 - val_accuracy: 0.6250 - val_loss: 0.6920\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 464ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6915\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 443ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6912\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 439ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 452ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 444ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 411ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 411ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 408ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 418ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.2984 - loss: 1.0251\n",
      "for 32: [0.6908219456672668, 0.625]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - accuracy: 0.6850 - loss: 1.2730 - val_accuracy: 0.6250 - val_loss: 0.6918\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 150ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6918\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 159ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6914\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 165ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6912\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 165ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 151ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 151ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 151ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 153ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.2984 - loss: 1.0252\n",
      "for 16: [0.6908431649208069, 0.625]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 107ms/step - accuracy: 0.7824 - loss: 0.9856 - val_accuracy: 0.8061 - val_loss: 0.7163\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 102ms/step - accuracy: 0.9482 - loss: 0.1356 - val_accuracy: 0.7885 - val_loss: 0.8407\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - accuracy: 0.9636 - loss: 0.1035 - val_accuracy: 0.7740 - val_loss: 0.7614\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 88ms/step - accuracy: 0.9750 - loss: 0.0715 - val_accuracy: 0.7772 - val_loss: 1.0338\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.9829 - loss: 0.0458 - val_accuracy: 0.8221 - val_loss: 1.0313\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 94ms/step - accuracy: 0.9865 - loss: 0.0377 - val_accuracy: 0.7885 - val_loss: 1.2629\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 101ms/step - accuracy: 0.9864 - loss: 0.0390 - val_accuracy: 0.7131 - val_loss: 1.6058\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 85ms/step - accuracy: 0.9910 - loss: 0.0344 - val_accuracy: 0.7933 - val_loss: 1.5577\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - accuracy: 0.9938 - loss: 0.0172 - val_accuracy: 0.7500 - val_loss: 1.7229\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.9959 - loss: 0.0119 - val_accuracy: 0.7179 - val_loss: 1.8608\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4801 - loss: 3.3013\n",
      "for 8: [1.860827922821045, 0.7179487347602844]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 85ms/step - accuracy: 0.7549 - loss: 0.4965 - val_accuracy: 0.8045 - val_loss: 0.6227\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9083 - loss: 0.2691 - val_accuracy: 0.8478 - val_loss: 0.4496\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9348 - loss: 0.1847 - val_accuracy: 0.7965 - val_loss: 0.6942\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.9556 - loss: 0.1322 - val_accuracy: 0.8045 - val_loss: 0.7614\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9532 - loss: 0.1297 - val_accuracy: 0.7644 - val_loss: 1.1680\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9622 - loss: 0.1066 - val_accuracy: 0.8077 - val_loss: 0.6368\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9414 - loss: 0.1511 - val_accuracy: 0.7388 - val_loss: 1.0282\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9577 - loss: 0.1201 - val_accuracy: 0.7660 - val_loss: 1.5997\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9769 - loss: 0.0635 - val_accuracy: 0.8269 - val_loss: 1.1454\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - accuracy: 0.9809 - loss: 0.0583 - val_accuracy: 0.7516 - val_loss: 2.1393\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5425 - loss: 4.0008\n",
      "for 4: [2.1392762660980225, 0.7516025900840759]\n"
     ]
    }
   ],
   "source": [
    "for n in [32, 16, 8, 4]:\n",
    "    model = models.Sequential(\n",
    "[\n",
    "    layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "    layers.Conv2D(n,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "    layers.Conv2D(int(n/2),kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_2'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_2'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train, epochs=10, validation_data=(X_test,y_test))\n",
    "    print(f'for {n}: {model.evaluate(x=X_test,y=y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ecc5d9",
   "metadata": {},
   "source": [
    "For 4: [2.1392762660980225, 0.7516025900840759]\n",
    "###### -----------------\n",
    "For 8: [1.860827922821045, 0.7179487347602844]\n",
    "###### -----------------\n",
    "For 16: [0.6908431649208069, 0.625]\n",
    "###### -----------------\n",
    "For 32: [0.6908219456672668, 0.625]\n",
    "### So, 4 is the best option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342d076",
   "metadata": {},
   "source": [
    "## Determine the best number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b7c7c93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.7995 - loss: 0.4301 - val_accuracy: 0.8141 - val_loss: 0.5445\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9431 - loss: 0.1618 - val_accuracy: 0.7356 - val_loss: 1.0944\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9691 - loss: 0.0799 - val_accuracy: 0.8189 - val_loss: 0.8071\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9720 - loss: 0.0704 - val_accuracy: 0.8045 - val_loss: 0.6937\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 72ms/step - accuracy: 0.9636 - loss: 0.0939 - val_accuracy: 0.7901 - val_loss: 1.2577\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9793 - loss: 0.0525 - val_accuracy: 0.7949 - val_loss: 1.7053\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 66ms/step - accuracy: 0.9914 - loss: 0.0280 - val_accuracy: 0.8045 - val_loss: 1.6895\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9929 - loss: 0.0219 - val_accuracy: 0.7901 - val_loss: 1.9349\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9909 - loss: 0.0267 - val_accuracy: 0.7244 - val_loss: 3.0298\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9904 - loss: 0.0250 - val_accuracy: 0.7516 - val_loss: 2.6652\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5320 - loss: 4.5654\n",
      "for 32: [2.665170669555664, 0.7516025900840759]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 83ms/step - accuracy: 0.7691 - loss: 0.5236 - val_accuracy: 0.6538 - val_loss: 0.7382\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.8285 - loss: 0.3937 - val_accuracy: 0.7067 - val_loss: 0.9215\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9100 - loss: 0.2032 - val_accuracy: 0.8029 - val_loss: 0.8739\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9581 - loss: 0.1124 - val_accuracy: 0.7772 - val_loss: 1.3101\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9684 - loss: 0.0802 - val_accuracy: 0.7837 - val_loss: 1.4857\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9786 - loss: 0.0621 - val_accuracy: 0.7740 - val_loss: 1.4454\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 70ms/step - accuracy: 0.9888 - loss: 0.0284 - val_accuracy: 0.7853 - val_loss: 1.7795\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 72ms/step - accuracy: 0.9936 - loss: 0.0245 - val_accuracy: 0.7580 - val_loss: 3.0107\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.9963 - loss: 0.0119 - val_accuracy: 0.7452 - val_loss: 3.9897\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.9929 - loss: 0.0205 - val_accuracy: 0.7035 - val_loss: 1.5479\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5085 - loss: 2.5286\n",
      "for 16: [1.5478638410568237, 0.7035256624221802]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 162ms/step - accuracy: 0.7369 - loss: 0.5515 - val_accuracy: 0.7067 - val_loss: 0.8058\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.8645 - loss: 0.3034 - val_accuracy: 0.7837 - val_loss: 0.9241\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.9130 - loss: 0.2079 - val_accuracy: 0.7628 - val_loss: 0.6724\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 66ms/step - accuracy: 0.9093 - loss: 0.2011 - val_accuracy: 0.7612 - val_loss: 1.1272\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9376 - loss: 0.1425 - val_accuracy: 0.7564 - val_loss: 1.3870\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.9566 - loss: 0.1054 - val_accuracy: 0.7644 - val_loss: 1.4448\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 71ms/step - accuracy: 0.9694 - loss: 0.0800 - val_accuracy: 0.7917 - val_loss: 1.5677\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 70ms/step - accuracy: 0.9665 - loss: 0.0861 - val_accuracy: 0.7532 - val_loss: 1.8314\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 85ms/step - accuracy: 0.9822 - loss: 0.0508 - val_accuracy: 0.7676 - val_loss: 1.7642\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9837 - loss: 0.0409 - val_accuracy: 0.7548 - val_loss: 2.4896\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5561 - loss: 4.3056\n",
      "for 8: [2.4895880222320557, 0.754807710647583]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.6980 - loss: 1.2917 - val_accuracy: 0.6250 - val_loss: 0.6919\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6917\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6913\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6911\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2984 - loss: 1.0251\n",
      "for 4: [0.6908310055732727, 0.625]\n"
     ]
    }
   ],
   "source": [
    "for n in [32, 16, 8, 4]:\n",
    "    model = models.Sequential(\n",
    "[\n",
    "    layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "    layers.Conv2D(4,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "    layers.Conv2D(2,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_2'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_2'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(n, activation='relu'),\n",
    "    layers.Dense(int(n/2), activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train, epochs=10, validation_data=(X_test,y_test))\n",
    "    print(f'for {n}: {model.evaluate(x=X_test,y=y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81252a4",
   "metadata": {},
   "source": [
    "For 4: [0.6908310055732727, 0.625]\n",
    "###### -----------------\n",
    "For 8: [2.4895880222320557, 0.754807710647583]\n",
    "###### -----------------\n",
    "For 16: [1.5478638410568237, 0.7035256624221802]\n",
    "###### -----------------\n",
    "For 32: [2.665170669555664, 0.7516025900840759]\n",
    "### So, 8 and 32 are the best option, but we will choose 8 to run faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0060af0",
   "metadata": {},
   "source": [
    "## Choose the best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "11d4f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 96ms/step - accuracy: 0.7162 - loss: 0.5967 - val_accuracy: 0.6250 - val_loss: 0.6396\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.7363 - loss: 0.4682 - val_accuracy: 0.6250 - val_loss: 0.5411\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.8191 - loss: 0.3467 - val_accuracy: 0.7260 - val_loss: 0.5103\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9022 - loss: 0.2993 - val_accuracy: 0.7388 - val_loss: 0.5151\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9256 - loss: 0.2732 - val_accuracy: 0.7484 - val_loss: 0.5225\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9360 - loss: 0.2551 - val_accuracy: 0.7612 - val_loss: 0.5354\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9438 - loss: 0.2425 - val_accuracy: 0.7500 - val_loss: 0.5819\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9469 - loss: 0.2330 - val_accuracy: 0.7564 - val_loss: 0.5860\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9533 - loss: 0.2251 - val_accuracy: 0.7580 - val_loss: 0.6164\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.9583 - loss: 0.2184 - val_accuracy: 0.7612 - val_loss: 0.6244\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5662 - loss: 1.1009\n",
      "for 0.0001: [0.6244033575057983, 0.7612179517745972]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - accuracy: 0.7617 - loss: 0.4454 - val_accuracy: 0.7532 - val_loss: 0.6470\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9605 - loss: 0.2176 - val_accuracy: 0.7308 - val_loss: 0.9396\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.9729 - loss: 0.1746 - val_accuracy: 0.7436 - val_loss: 1.0950\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9789 - loss: 0.1414 - val_accuracy: 0.7596 - val_loss: 1.0081\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9867 - loss: 0.1143 - val_accuracy: 0.7452 - val_loss: 1.4714\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9875 - loss: 0.0953 - val_accuracy: 0.7356 - val_loss: 1.8716\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.9897 - loss: 0.0836 - val_accuracy: 0.7388 - val_loss: 2.0121\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 66ms/step - accuracy: 0.9887 - loss: 0.0736 - val_accuracy: 0.7660 - val_loss: 1.9235\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9892 - loss: 0.0657 - val_accuracy: 0.7660 - val_loss: 2.0673\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9888 - loss: 0.0622 - val_accuracy: 0.7436 - val_loss: 2.6289\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5236 - loss: 4.8208\n",
      "for 0.001: [2.628934860229492, 0.7435897588729858]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 83ms/step - accuracy: 0.7790 - loss: 0.4276 - val_accuracy: 0.7917 - val_loss: 0.6637\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9534 - loss: 0.1257 - val_accuracy: 0.7676 - val_loss: 1.3573\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9757 - loss: 0.0666 - val_accuracy: 0.7436 - val_loss: 1.7620\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9822 - loss: 0.0481 - val_accuracy: 0.8077 - val_loss: 1.7166\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9767 - loss: 0.0577 - val_accuracy: 0.7436 - val_loss: 2.5453\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9804 - loss: 0.0557 - val_accuracy: 0.7420 - val_loss: 3.1734\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9935 - loss: 0.0150 - val_accuracy: 0.7708 - val_loss: 4.5395\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9952 - loss: 0.0117 - val_accuracy: 0.7436 - val_loss: 4.3587\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9920 - loss: 0.0196 - val_accuracy: 0.7965 - val_loss: 1.6635\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9804 - loss: 0.0559 - val_accuracy: 0.7853 - val_loss: 2.1091\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6185 - loss: 3.4142\n",
      "for 0.01: [2.1090946197509766, 0.7852563858032227]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 91ms/step - accuracy: 0.7049 - loss: 0.5953 - val_accuracy: 0.6250 - val_loss: 0.7002\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.7363 - loss: 0.5795 - val_accuracy: 0.6250 - val_loss: 0.7005\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.7363 - loss: 0.5797 - val_accuracy: 0.6250 - val_loss: 0.7006\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7363 - loss: 0.5798 - val_accuracy: 0.6250 - val_loss: 0.7007\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7363 - loss: 0.5798 - val_accuracy: 0.6250 - val_loss: 0.7007\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7363 - loss: 0.5798 - val_accuracy: 0.6250 - val_loss: 0.7007\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.7363 - loss: 0.5798 - val_accuracy: 0.6250 - val_loss: 0.7007\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 66ms/step - accuracy: 0.7363 - loss: 0.5798 - val_accuracy: 0.6250 - val_loss: 0.7007\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.7363 - loss: 0.5798 - val_accuracy: 0.6250 - val_loss: 0.7007\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.7363 - loss: 0.5798 - val_accuracy: 0.6250 - val_loss: 0.7007\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2984 - loss: 1.0622\n",
      "for 0.1: [0.7007248997688293, 0.625]\n"
     ]
    }
   ],
   "source": [
    "for n in [0.0001, 0.001, 0.01, 0.1]:\n",
    "    model = models.Sequential(\n",
    "[\n",
    "    layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "    layers.Conv2D(4,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "    layers.Conv2D(2,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_2'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_2'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=n),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train, epochs=10, validation_data=(X_test,y_test))\n",
    "    print(f'for {n}: {model.evaluate(x=X_test,y=y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86196134",
   "metadata": {},
   "source": [
    "For 0.0001: [0.6244033575057983, 0.7612179517745972]\n",
    "###### -----------------\n",
    "For 0.001: [2.628934860229492, 0.7435897588729858]\n",
    "###### -----------------\n",
    "For 0.01: [2.1090946197509766, 0.7852563858032227]\n",
    "###### -----------------\n",
    "For 0.1: [0.7007248997688293, 0.625]\n",
    "### So, 0.01 is the best option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc979234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 83ms/step - accuracy: 0.6905 - loss: 0.8296 - val_accuracy: 0.6250 - val_loss: 0.6774\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.7363 - loss: 0.5772 - val_accuracy: 0.6250 - val_loss: 0.6931\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6943\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6941\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6940\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6939\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6938\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6938\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6937\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6937\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2984 - loss: 1.0362\n",
      "for 0.005: [0.6936720609664917, 0.625]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.8061 - loss: 0.3779 - val_accuracy: 0.8654 - val_loss: 0.5101\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9478 - loss: 0.1616 - val_accuracy: 0.8205 - val_loss: 0.8530\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9616 - loss: 0.1013 - val_accuracy: 0.7788 - val_loss: 1.1349\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9734 - loss: 0.0781 - val_accuracy: 0.7163 - val_loss: 2.5558\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9781 - loss: 0.0668 - val_accuracy: 0.7404 - val_loss: 2.0337\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9837 - loss: 0.0483 - val_accuracy: 0.7772 - val_loss: 1.6959\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9890 - loss: 0.0404 - val_accuracy: 0.7676 - val_loss: 1.9747\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9893 - loss: 0.0354 - val_accuracy: 0.7853 - val_loss: 1.9646\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9865 - loss: 0.0394 - val_accuracy: 0.7660 - val_loss: 2.9302\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9917 - loss: 0.0296 - val_accuracy: 0.7612 - val_loss: 3.1070\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5803 - loss: 5.4632\n",
      "for 0.007: [3.1069881916046143, 0.7612179517745972]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 85ms/step - accuracy: 0.7165 - loss: 0.5752 - val_accuracy: 0.8173 - val_loss: 0.4290\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9287 - loss: 0.2305 - val_accuracy: 0.8638 - val_loss: 0.3610\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9485 - loss: 0.1549 - val_accuracy: 0.8606 - val_loss: 0.5480\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9576 - loss: 0.1301 - val_accuracy: 0.8237 - val_loss: 0.9028\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9597 - loss: 0.1256 - val_accuracy: 0.7821 - val_loss: 1.4520\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9635 - loss: 0.1077 - val_accuracy: 0.8189 - val_loss: 1.2778\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9654 - loss: 0.1048 - val_accuracy: 0.7628 - val_loss: 2.3226\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9783 - loss: 0.0731 - val_accuracy: 0.8077 - val_loss: 1.6782\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9797 - loss: 0.0746 - val_accuracy: 0.7740 - val_loss: 2.4257\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9835 - loss: 0.0559 - val_accuracy: 0.8253 - val_loss: 1.7491\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7227 - loss: 2.7433\n",
      "for 0.01: [1.7491086721420288, 0.8253205418586731]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.7478 - loss: 2.4499 - val_accuracy: 0.7548 - val_loss: 1.0034\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.8854 - loss: 0.2669 - val_accuracy: 0.7788 - val_loss: 0.9865\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9095 - loss: 0.2104 - val_accuracy: 0.7804 - val_loss: 1.1143\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9264 - loss: 0.1840 - val_accuracy: 0.7821 - val_loss: 1.2116\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9368 - loss: 0.1570 - val_accuracy: 0.7356 - val_loss: 1.7592\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9322 - loss: 0.1621 - val_accuracy: 0.7516 - val_loss: 0.9552\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9393 - loss: 0.1532 - val_accuracy: 0.7484 - val_loss: 1.9921\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9497 - loss: 0.1170 - val_accuracy: 0.7708 - val_loss: 2.1770\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9693 - loss: 0.0811 - val_accuracy: 0.7276 - val_loss: 2.5861\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9588 - loss: 0.1086 - val_accuracy: 0.7500 - val_loss: 1.5593\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5431 - loss: 2.7193\n",
      "for 0.03: [1.5592596530914307, 0.75]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 86ms/step - accuracy: 0.7415 - loss: 0.5459 - val_accuracy: 0.7788 - val_loss: 0.7620\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.7968 - loss: 0.4187 - val_accuracy: 0.6250 - val_loss: 0.6960\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.7363 - loss: 0.5778 - val_accuracy: 0.6250 - val_loss: 0.6962\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.7363 - loss: 0.5778 - val_accuracy: 0.6250 - val_loss: 0.6965\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.7363 - loss: 0.5779 - val_accuracy: 0.6250 - val_loss: 0.6967\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.7363 - loss: 0.5780 - val_accuracy: 0.6250 - val_loss: 0.6969\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.7363 - loss: 0.5780 - val_accuracy: 0.6250 - val_loss: 0.6970\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.7363 - loss: 0.5780 - val_accuracy: 0.6250 - val_loss: 0.6970\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.7363 - loss: 0.5780 - val_accuracy: 0.6250 - val_loss: 0.6971\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.7363 - loss: 0.5780 - val_accuracy: 0.6250 - val_loss: 0.6971\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2984 - loss: 1.0491\n",
      "for 0.06: [0.6971079111099243, 0.625]\n"
     ]
    }
   ],
   "source": [
    "for n in [0.005, 0.007, 0.01, 0.03, 0.06]:\n",
    "    model = models.Sequential(\n",
    "[\n",
    "    layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "    layers.Conv2D(4,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "    layers.Conv2D(2,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_2'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_2'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=n),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train, epochs=10, validation_data=(X_test,y_test))\n",
    "    print(f'for {n}: {model.evaluate(x=X_test,y=y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0da498",
   "metadata": {},
   "source": [
    "For 0.005: [0.6936720609664917, 0.625]\n",
    "###### -----------------\n",
    "for 0.007: [3.1069881916046143, 0.7612179517745972]\n",
    "###### -----------------\n",
    "for 0.01: [1.7491086721420288, 0.8253205418586731]\n",
    "###### -----------------\n",
    "for 0.03: [1.5592596530914307, 0.75]\n",
    "###### -----------------\n",
    "for 0.06: [0.6971079111099243, 0.625]\n",
    "### So, 0.01 is still the best option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6eec5c",
   "metadata": {},
   "source": [
    "## Determine best number of batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1a548402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.7649 - loss: 0.4790 - val_accuracy: 0.8125 - val_loss: 0.5684\n",
      "Epoch 2/10\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.9287 - loss: 0.1862 - val_accuracy: 0.7933 - val_loss: 0.7162\n",
      "Epoch 3/10\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.9568 - loss: 0.1137 - val_accuracy: 0.7452 - val_loss: 1.5171\n",
      "Epoch 4/10\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.9720 - loss: 0.0742 - val_accuracy: 0.7917 - val_loss: 1.6461\n",
      "Epoch 5/10\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.9756 - loss: 0.0583 - val_accuracy: 0.7885 - val_loss: 1.3839\n",
      "Epoch 6/10\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.9865 - loss: 0.0322 - val_accuracy: 0.7548 - val_loss: 2.0657\n",
      "Epoch 7/10\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.9853 - loss: 0.0403 - val_accuracy: 0.7372 - val_loss: 2.5989\n",
      "Epoch 8/10\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.9878 - loss: 0.0333 - val_accuracy: 0.7372 - val_loss: 3.1884\n",
      "Epoch 9/10\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.9882 - loss: 0.0380 - val_accuracy: 0.7404 - val_loss: 3.2914\n",
      "Epoch 10/10\n",
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.9850 - loss: 0.0424 - val_accuracy: 0.7356 - val_loss: 4.5851\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5176 - loss: 8.6059\n",
      "for 16: [4.585075855255127, 0.7355769276618958]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.7510 - loss: 0.5296 - val_accuracy: 0.7484 - val_loss: 0.6917\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9215 - loss: 0.2250 - val_accuracy: 0.7788 - val_loss: 1.5896\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9510 - loss: 0.1424 - val_accuracy: 0.7644 - val_loss: 1.7541\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9698 - loss: 0.0939 - val_accuracy: 0.7404 - val_loss: 2.5214\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9802 - loss: 0.0693 - val_accuracy: 0.7660 - val_loss: 2.9272\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9830 - loss: 0.0567 - val_accuracy: 0.7933 - val_loss: 2.1009\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9821 - loss: 0.0598 - val_accuracy: 0.7484 - val_loss: 3.0401\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9865 - loss: 0.0501 - val_accuracy: 0.7564 - val_loss: 3.5215\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9927 - loss: 0.0320 - val_accuracy: 0.7564 - val_loss: 4.2311\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9816 - loss: 0.0645 - val_accuracy: 0.7564 - val_loss: 3.0855\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5635 - loss: 5.1696\n",
      "for 32: [3.0854618549346924, 0.7564102411270142]\n",
      "Epoch 1/10\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 205ms/step - accuracy: 0.7186 - loss: 0.5939 - val_accuracy: 0.6250 - val_loss: 0.7060\n",
      "Epoch 2/10\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - accuracy: 0.7352 - loss: 0.4692 - val_accuracy: 0.7821 - val_loss: 0.6656\n",
      "Epoch 3/10\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.8602 - loss: 0.3134 - val_accuracy: 0.7532 - val_loss: 0.8066\n",
      "Epoch 4/10\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - accuracy: 0.8887 - loss: 0.2590 - val_accuracy: 0.7596 - val_loss: 1.0016\n",
      "Epoch 5/10\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9252 - loss: 0.1977 - val_accuracy: 0.8526 - val_loss: 0.7130\n",
      "Epoch 6/10\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.9374 - loss: 0.1644 - val_accuracy: 0.8157 - val_loss: 1.2968\n",
      "Epoch 7/10\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 104ms/step - accuracy: 0.9523 - loss: 0.1240 - val_accuracy: 0.7580 - val_loss: 2.3612\n",
      "Epoch 8/10\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.9601 - loss: 0.1119 - val_accuracy: 0.7564 - val_loss: 0.8041\n",
      "Epoch 9/10\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.8673 - loss: 0.2894 - val_accuracy: 0.7965 - val_loss: 0.9007\n",
      "Epoch 10/10\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.9120 - loss: 0.2033 - val_accuracy: 0.7356 - val_loss: 1.4685\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5278 - loss: 2.5581\n",
      "for 64: [1.46847665309906, 0.7355769276618958]\n",
      "Epoch 1/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 308ms/step - accuracy: 0.6747 - loss: 0.6473 - val_accuracy: 0.7821 - val_loss: 0.5424\n",
      "Epoch 2/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - accuracy: 0.8798 - loss: 0.4264 - val_accuracy: 0.7003 - val_loss: 0.6092\n",
      "Epoch 3/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 203ms/step - accuracy: 0.8863 - loss: 0.3340 - val_accuracy: 0.7404 - val_loss: 0.5293\n",
      "Epoch 4/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 202ms/step - accuracy: 0.9035 - loss: 0.2857 - val_accuracy: 0.7756 - val_loss: 0.4905\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.9243 - loss: 0.2270 - val_accuracy: 0.7821 - val_loss: 0.4924\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 197ms/step - accuracy: 0.9436 - loss: 0.1807 - val_accuracy: 0.7949 - val_loss: 0.5082\n",
      "Epoch 7/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.9561 - loss: 0.1474 - val_accuracy: 0.8125 - val_loss: 0.4888\n",
      "Epoch 8/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 196ms/step - accuracy: 0.9666 - loss: 0.1141 - val_accuracy: 0.7869 - val_loss: 0.6064\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 204ms/step - accuracy: 0.9853 - loss: 0.0659 - val_accuracy: 0.7404 - val_loss: 0.7869\n",
      "Epoch 10/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 196ms/step - accuracy: 0.9902 - loss: 0.0497 - val_accuracy: 0.7484 - val_loss: 0.7735\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5218 - loss: 1.4323\n",
      "for 128: [0.7734513282775879, 0.7483974099159241]\n"
     ]
    }
   ],
   "source": [
    "for n in [16, 32, 64, 128]:\n",
    "    model = models.Sequential(\n",
    "[\n",
    "    layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "    layers.Conv2D(4,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "    layers.Conv2D(2,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_2'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_2'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train, batch_size= n,epochs=10,validation_data=(X_test,y_test))\n",
    "    print(f'for {n}: {model.evaluate(x=X_test,y=y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f182d",
   "metadata": {},
   "source": [
    "for 16: [4.585075855255127, 0.7355769276618958]\n",
    "###### -----------------\n",
    "for 32: [3.0854618549346924, 0.7564102411270142]\n",
    "###### -----------------\n",
    "for 64: [1.46847665309906, 0.7355769276618958]\n",
    "###### -----------------\n",
    "for 128: [0.7734513282775879, 0.7483974099159241]\n",
    "### So, 32 (Defualt value) is the best option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb028a1b",
   "metadata": {},
   "source": [
    "## Determine the best number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c6671b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - accuracy: 0.7358 - loss: 0.5025 - val_accuracy: 0.8013 - val_loss: 0.7045\n",
      "Epoch 2/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9193 - loss: 0.2335 - val_accuracy: 0.7756 - val_loss: 0.6416\n",
      "Epoch 3/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9001 - loss: 0.2362 - val_accuracy: 0.8446 - val_loss: 0.6792\n",
      "Epoch 4/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 71ms/step - accuracy: 0.9539 - loss: 0.1182 - val_accuracy: 0.7628 - val_loss: 1.3723\n",
      "Epoch 5/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.9715 - loss: 0.0723 - val_accuracy: 0.7420 - val_loss: 2.1109\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.5230 - loss: 3.7830\n",
      "for 5: [2.1108760833740234, 0.7419871687889099]\n",
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 105ms/step - accuracy: 0.7233 - loss: 0.6081 - val_accuracy: 0.6250 - val_loss: 0.6937\n",
      "Epoch 2/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6936\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6933\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6930\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6929\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6928\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.7363 - loss: 0.5770 - val_accuracy: 0.6250 - val_loss: 0.6926\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6925\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6924\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6922\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2984 - loss: 1.0306\n",
      "for 10: [0.692223846912384, 0.625]\n",
      "Epoch 1/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 86ms/step - accuracy: 0.7225 - loss: 0.8198 - val_accuracy: 0.6250 - val_loss: 0.6913\n",
      "Epoch 2/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6907\n",
      "Epoch 3/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6907\n",
      "Epoch 4/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "Epoch 5/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "Epoch 6/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 7/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 8/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 9/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 10/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 11/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 12/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 13/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 14/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 15/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 16/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 17/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6910\n",
      "Epoch 18/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 19/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6909\n",
      "Epoch 20/20\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.7363 - loss: 0.5769 - val_accuracy: 0.6250 - val_loss: 0.6908\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2984 - loss: 1.0252\n",
      "for 20: [0.6908404231071472, 0.625]\n",
      "Epoch 1/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 88ms/step - accuracy: 0.7799 - loss: 0.4745 - val_accuracy: 0.7628 - val_loss: 0.6035\n",
      "Epoch 2/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.8979 - loss: 0.2474 - val_accuracy: 0.7965 - val_loss: 0.7961\n",
      "Epoch 3/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 70ms/step - accuracy: 0.9596 - loss: 0.0999 - val_accuracy: 0.7548 - val_loss: 1.3838\n",
      "Epoch 4/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9610 - loss: 0.0985 - val_accuracy: 0.7356 - val_loss: 1.3930\n",
      "Epoch 5/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - accuracy: 0.9842 - loss: 0.0424 - val_accuracy: 0.7452 - val_loss: 1.9874\n",
      "Epoch 6/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.9927 - loss: 0.0223 - val_accuracy: 0.7388 - val_loss: 2.5336\n",
      "Epoch 7/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9903 - loss: 0.0289 - val_accuracy: 0.7724 - val_loss: 2.1472\n",
      "Epoch 8/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9916 - loss: 0.0252 - val_accuracy: 0.7788 - val_loss: 2.0870\n",
      "Epoch 9/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9948 - loss: 0.0169 - val_accuracy: 0.7564 - val_loss: 2.6424\n",
      "Epoch 10/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9969 - loss: 0.0058 - val_accuracy: 0.7468 - val_loss: 3.7996\n",
      "Epoch 11/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.7628 - val_loss: 3.2305\n",
      "Epoch 12/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9882 - loss: 0.0364 - val_accuracy: 0.7484 - val_loss: 1.4578\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9660 - loss: 0.0921 - val_accuracy: 0.7516 - val_loss: 2.3178\n",
      "Epoch 14/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9905 - loss: 0.0290 - val_accuracy: 0.7644 - val_loss: 2.8046\n",
      "Epoch 15/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9999 - loss: 0.0028 - val_accuracy: 0.7660 - val_loss: 3.6814\n",
      "Epoch 16/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.7612 - val_loss: 4.2175\n",
      "Epoch 17/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9999 - loss: 4.1765e-04 - val_accuracy: 0.7612 - val_loss: 4.4713\n",
      "Epoch 18/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9999 - loss: 2.5381e-04 - val_accuracy: 0.7596 - val_loss: 4.6788\n",
      "Epoch 19/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9999 - loss: 2.1835e-04 - val_accuracy: 0.7628 - val_loss: 4.8433\n",
      "Epoch 20/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9999 - loss: 1.9647e-04 - val_accuracy: 0.7628 - val_loss: 4.9562\n",
      "Epoch 21/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9999 - loss: 1.8158e-04 - val_accuracy: 0.7628 - val_loss: 5.0949\n",
      "Epoch 22/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.7612 - val_loss: 1.9597\n",
      "Epoch 23/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 66ms/step - accuracy: 0.9931 - loss: 0.0219 - val_accuracy: 0.7724 - val_loss: 3.0485\n",
      "Epoch 24/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9960 - loss: 0.0115 - val_accuracy: 0.7724 - val_loss: 2.7936\n",
      "Epoch 25/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.9981 - loss: 0.0039 - val_accuracy: 0.7740 - val_loss: 3.4255\n",
      "Epoch 26/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 7.8799e-04 - val_accuracy: 0.7660 - val_loss: 4.7877\n",
      "Epoch 27/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.0884e-04 - val_accuracy: 0.7660 - val_loss: 5.0582\n",
      "Epoch 28/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.1219e-04 - val_accuracy: 0.7660 - val_loss: 5.3275\n",
      "Epoch 29/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 6.9029e-05 - val_accuracy: 0.7660 - val_loss: 5.6145\n",
      "Epoch 30/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 3.4446e-05 - val_accuracy: 0.7660 - val_loss: 5.7788\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5794 - loss: 10.2168\n",
      "for 30: [5.778837203979492, 0.7660256624221802]\n",
      "Epoch 1/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.8006 - loss: 0.4684 - val_accuracy: 0.8141 - val_loss: 0.4908\n",
      "Epoch 2/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9331 - loss: 0.1711 - val_accuracy: 0.7644 - val_loss: 0.8672\n",
      "Epoch 3/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9709 - loss: 0.0874 - val_accuracy: 0.7804 - val_loss: 0.7901\n",
      "Epoch 4/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9728 - loss: 0.0778 - val_accuracy: 0.7804 - val_loss: 0.9957\n",
      "Epoch 5/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9748 - loss: 0.0692 - val_accuracy: 0.7596 - val_loss: 1.3082\n",
      "Epoch 6/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9866 - loss: 0.0398 - val_accuracy: 0.7580 - val_loss: 1.7121\n",
      "Epoch 7/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.9830 - loss: 0.0442 - val_accuracy: 0.7484 - val_loss: 1.8499\n",
      "Epoch 8/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9909 - loss: 0.0248 - val_accuracy: 0.7420 - val_loss: 2.1120\n",
      "Epoch 9/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.9950 - loss: 0.0172 - val_accuracy: 0.7564 - val_loss: 1.7665\n",
      "Epoch 10/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9908 - loss: 0.0230 - val_accuracy: 0.7628 - val_loss: 1.5597\n",
      "Epoch 11/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9872 - loss: 0.0369 - val_accuracy: 0.7853 - val_loss: 2.0104\n",
      "Epoch 12/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9935 - loss: 0.0180 - val_accuracy: 0.7500 - val_loss: 2.3290\n",
      "Epoch 13/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9966 - loss: 0.0086 - val_accuracy: 0.7596 - val_loss: 1.8461\n",
      "Epoch 14/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9968 - loss: 0.0079 - val_accuracy: 0.7292 - val_loss: 2.4582\n",
      "Epoch 15/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9958 - loss: 0.0173 - val_accuracy: 0.7548 - val_loss: 2.0079\n",
      "Epoch 16/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.7708 - val_loss: 2.1050\n",
      "Epoch 17/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9940 - loss: 0.0121 - val_accuracy: 0.7292 - val_loss: 2.5933\n",
      "Epoch 18/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9954 - loss: 0.0119 - val_accuracy: 0.8029 - val_loss: 1.4984\n",
      "Epoch 19/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9935 - loss: 0.0145 - val_accuracy: 0.7404 - val_loss: 2.6045\n",
      "Epoch 20/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9985 - loss: 0.0059 - val_accuracy: 0.7115 - val_loss: 2.7946\n",
      "Epoch 21/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.9956 - loss: 0.0171 - val_accuracy: 0.7612 - val_loss: 2.7017\n",
      "Epoch 22/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.9920 - loss: 0.0241 - val_accuracy: 0.7388 - val_loss: 3.2011\n",
      "Epoch 23/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9949 - loss: 0.0118 - val_accuracy: 0.7500 - val_loss: 2.6722\n",
      "Epoch 24/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9969 - loss: 0.0104 - val_accuracy: 0.7260 - val_loss: 2.8078\n",
      "Epoch 25/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9984 - loss: 0.0034 - val_accuracy: 0.7532 - val_loss: 2.5991\n",
      "Epoch 26/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.7724 - val_loss: 1.0335\n",
      "Epoch 27/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9945 - loss: 0.0193 - val_accuracy: 0.7292 - val_loss: 4.6831\n",
      "Epoch 28/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9989 - loss: 0.0021 - val_accuracy: 0.7404 - val_loss: 3.4311\n",
      "Epoch 29/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9948 - loss: 0.0139 - val_accuracy: 0.7436 - val_loss: 4.3253\n",
      "Epoch 30/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.9991 - loss: 0.0018 - val_accuracy: 0.7260 - val_loss: 5.5224\n",
      "Epoch 31/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9870 - loss: 0.0478 - val_accuracy: 0.7324 - val_loss: 2.0667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9942 - loss: 0.0159 - val_accuracy: 0.7420 - val_loss: 3.2827\n",
      "Epoch 33/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.7163 - val_loss: 3.7855\n",
      "Epoch 34/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9969 - loss: 0.0067 - val_accuracy: 0.7372 - val_loss: 1.9582\n",
      "Epoch 35/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9975 - loss: 0.0088 - val_accuracy: 0.7324 - val_loss: 2.8829\n",
      "Epoch 36/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9966 - loss: 0.0098 - val_accuracy: 0.7003 - val_loss: 1.7243\n",
      "Epoch 37/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9966 - loss: 0.0155 - val_accuracy: 0.7388 - val_loss: 2.9803\n",
      "Epoch 38/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.7388 - val_loss: 2.8800\n",
      "Epoch 39/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9990 - loss: 0.0046 - val_accuracy: 0.7436 - val_loss: 3.7295\n",
      "Epoch 40/40\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9989 - loss: 0.0021 - val_accuracy: 0.7372 - val_loss: 4.0362\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5282 - loss: 6.9821\n",
      "for 40: [4.036153316497803, 0.7371794581413269]\n",
      "Epoch 1/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.7591 - loss: 0.4850 - val_accuracy: 0.8365 - val_loss: 0.4362\n",
      "Epoch 2/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9304 - loss: 0.1907 - val_accuracy: 0.6250 - val_loss: 0.5688\n",
      "Epoch 3/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9212 - loss: 0.1733 - val_accuracy: 0.7580 - val_loss: 0.7389\n",
      "Epoch 4/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9601 - loss: 0.1113 - val_accuracy: 0.7821 - val_loss: 0.7444\n",
      "Epoch 5/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9668 - loss: 0.0880 - val_accuracy: 0.7660 - val_loss: 1.3357\n",
      "Epoch 6/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9732 - loss: 0.0767 - val_accuracy: 0.7628 - val_loss: 1.4047\n",
      "Epoch 7/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9827 - loss: 0.0463 - val_accuracy: 0.7436 - val_loss: 1.7615\n",
      "Epoch 8/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9731 - loss: 0.0695 - val_accuracy: 0.7420 - val_loss: 1.2236\n",
      "Epoch 9/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9771 - loss: 0.0555 - val_accuracy: 0.7821 - val_loss: 1.2534\n",
      "Epoch 10/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9896 - loss: 0.0287 - val_accuracy: 0.7452 - val_loss: 1.2149\n",
      "Epoch 11/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9862 - loss: 0.0334 - val_accuracy: 0.7244 - val_loss: 2.6146\n",
      "Epoch 12/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9915 - loss: 0.0175 - val_accuracy: 0.7308 - val_loss: 2.8447\n",
      "Epoch 13/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9936 - loss: 0.0135 - val_accuracy: 0.7163 - val_loss: 3.2215\n",
      "Epoch 14/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9947 - loss: 0.0109 - val_accuracy: 0.7147 - val_loss: 3.8105\n",
      "Epoch 15/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9951 - loss: 0.0141 - val_accuracy: 0.7660 - val_loss: 2.4153\n",
      "Epoch 16/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9960 - loss: 0.0100 - val_accuracy: 0.7436 - val_loss: 3.2819\n",
      "Epoch 17/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9957 - loss: 0.0084 - val_accuracy: 0.7580 - val_loss: 3.1243\n",
      "Epoch 18/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9965 - loss: 0.0085 - val_accuracy: 0.7821 - val_loss: 3.3271\n",
      "Epoch 19/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9907 - loss: 0.0283 - val_accuracy: 0.7612 - val_loss: 2.7499\n",
      "Epoch 20/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9977 - loss: 0.0052 - val_accuracy: 0.7484 - val_loss: 2.9404\n",
      "Epoch 21/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9975 - loss: 0.0092 - val_accuracy: 0.7436 - val_loss: 3.0378\n",
      "Epoch 22/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9977 - loss: 0.0081 - val_accuracy: 0.7500 - val_loss: 3.1372\n",
      "Epoch 23/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - accuracy: 0.9948 - loss: 0.0198 - val_accuracy: 0.7356 - val_loss: 3.2661\n",
      "Epoch 24/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 0.7388 - val_loss: 4.2649\n",
      "Epoch 25/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9960 - loss: 0.0099 - val_accuracy: 0.7163 - val_loss: 5.4235\n",
      "Epoch 26/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9905 - loss: 0.0264 - val_accuracy: 0.7420 - val_loss: 2.7198\n",
      "Epoch 27/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9965 - loss: 0.0137 - val_accuracy: 0.7596 - val_loss: 2.0505\n",
      "Epoch 28/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9953 - loss: 0.0137 - val_accuracy: 0.8173 - val_loss: 1.8605\n",
      "Epoch 29/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9921 - loss: 0.0213 - val_accuracy: 0.7564 - val_loss: 3.2399\n",
      "Epoch 30/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9977 - loss: 0.0091 - val_accuracy: 0.7740 - val_loss: 2.6718\n",
      "Epoch 31/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9983 - loss: 0.0041 - val_accuracy: 0.7580 - val_loss: 2.3988\n",
      "Epoch 32/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.7821 - val_loss: 3.3505\n",
      "Epoch 33/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9987 - loss: 0.0029 - val_accuracy: 0.7949 - val_loss: 3.3629\n",
      "Epoch 34/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9989 - loss: 0.0029 - val_accuracy: 0.7420 - val_loss: 5.0635\n",
      "Epoch 35/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7420 - val_loss: 5.0727\n",
      "Epoch 36/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7420 - val_loss: 5.0976\n",
      "Epoch 37/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7420 - val_loss: 5.1275\n",
      "Epoch 38/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7420 - val_loss: 5.1585\n",
      "Epoch 39/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7420 - val_loss: 5.1892\n",
      "Epoch 40/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7436 - val_loss: 5.2186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7436 - val_loss: 5.2465\n",
      "Epoch 42/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7436 - val_loss: 5.2728\n",
      "Epoch 43/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7436 - val_loss: 5.2978\n",
      "Epoch 44/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7420 - val_loss: 5.3212\n",
      "Epoch 45/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7420 - val_loss: 5.3428\n",
      "Epoch 46/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7436 - val_loss: 5.3628\n",
      "Epoch 47/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7436 - val_loss: 5.3814\n",
      "Epoch 48/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7436 - val_loss: 5.3985\n",
      "Epoch 49/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7436 - val_loss: 5.4139\n",
      "Epoch 50/50\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.7452 - val_loss: 5.4275\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5319 - loss: 9.5753 \n",
      "for 50: [5.427529811859131, 0.745192289352417]\n"
     ]
    }
   ],
   "source": [
    "for n in [5, 10, 20, 30, 40, 50]:\n",
    "    model = models.Sequential(\n",
    "[\n",
    "    layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "    layers.Conv2D(4,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "    layers.Conv2D(2,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_2'),\n",
    "    layers.MaxPool2D((2,2),name='max_pool_2'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train, epochs=n,validation_data=(X_test,y_test))\n",
    "    print(f'for {n}: {model.evaluate(x=X_test,y=y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd929a",
   "metadata": {},
   "source": [
    "for 5: [2.1108760833740234, 0.7419871687889099]\n",
    "###### -----------------\n",
    "for 10: [0.692223846912384, 0.625]\n",
    "###### -----------------\n",
    "for 30: [5.778837203979492, 0.7660256624221802]\n",
    "###### -----------------\n",
    "for 40: [4.036153316497803, 0.7371794581413269]\n",
    "###### -----------------\n",
    "for 50: [5.427529811859131, 0.745192289352417]\n",
    "### So, 30 is the best option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24989754",
   "metadata": {},
   "source": [
    "## Train the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4de467a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 79ms/step - accuracy: 0.7358 - loss: 0.8213 - val_accuracy: 0.8077 - val_loss: 0.4562\n",
      "Epoch 2/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.8977 - loss: 0.5205 - val_accuracy: 0.7452 - val_loss: 0.5260\n",
      "Epoch 3/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9007 - loss: 0.5210 - val_accuracy: 0.7885 - val_loss: 0.5369\n",
      "Epoch 4/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9083 - loss: 0.4616 - val_accuracy: 0.7724 - val_loss: 0.6779\n",
      "Epoch 5/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9144 - loss: 0.4446 - val_accuracy: 0.7853 - val_loss: 0.8582\n",
      "Epoch 6/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9205 - loss: 0.4426 - val_accuracy: 0.7708 - val_loss: 0.8914\n",
      "Epoch 7/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9249 - loss: 0.4133 - val_accuracy: 0.7708 - val_loss: 1.0478\n",
      "Epoch 8/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9183 - loss: 0.4306 - val_accuracy: 0.7965 - val_loss: 0.4769\n",
      "Epoch 9/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9300 - loss: 0.4058 - val_accuracy: 0.7901 - val_loss: 1.0821\n",
      "Epoch 10/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9171 - loss: 0.4611 - val_accuracy: 0.7484 - val_loss: 1.1439\n",
      "Epoch 11/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9259 - loss: 0.4023 - val_accuracy: 0.7500 - val_loss: 0.6479\n",
      "Epoch 12/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9530 - loss: 0.3140 - val_accuracy: 0.7500 - val_loss: 1.2713\n",
      "Epoch 13/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9412 - loss: 0.4043 - val_accuracy: 0.7596 - val_loss: 0.9901\n",
      "Epoch 14/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9492 - loss: 0.3303 - val_accuracy: 0.7628 - val_loss: 0.9515\n",
      "Epoch 15/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9588 - loss: 0.2850 - val_accuracy: 0.7917 - val_loss: 0.9252\n",
      "Epoch 16/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9626 - loss: 0.2628 - val_accuracy: 0.7788 - val_loss: 0.9401\n",
      "Epoch 17/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9531 - loss: 0.3150 - val_accuracy: 0.7724 - val_loss: 0.8634\n",
      "Epoch 18/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9650 - loss: 0.2539 - val_accuracy: 0.7644 - val_loss: 0.8037\n",
      "Epoch 19/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9615 - loss: 0.2708 - val_accuracy: 0.7516 - val_loss: 1.2523\n",
      "Epoch 20/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9579 - loss: 0.2921 - val_accuracy: 0.7532 - val_loss: 1.2016\n",
      "Epoch 21/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9551 - loss: 0.2980 - val_accuracy: 0.7612 - val_loss: 0.9980\n",
      "Epoch 22/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9696 - loss: 0.2338 - val_accuracy: 0.7580 - val_loss: 0.7284\n",
      "Epoch 23/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9593 - loss: 0.2862 - val_accuracy: 0.7484 - val_loss: 1.4927\n",
      "Epoch 24/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9640 - loss: 0.2599 - val_accuracy: 0.7756 - val_loss: 1.6663\n",
      "Epoch 25/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9535 - loss: 0.3069 - val_accuracy: 0.7372 - val_loss: 1.4772\n",
      "Epoch 26/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9546 - loss: 0.3022 - val_accuracy: 0.7516 - val_loss: 0.8819\n",
      "Epoch 27/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9582 - loss: 0.2800 - val_accuracy: 0.7804 - val_loss: 0.9389\n",
      "Epoch 28/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9563 - loss: 0.2862 - val_accuracy: 0.7612 - val_loss: 1.6288\n",
      "Epoch 29/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9664 - loss: 0.2493 - val_accuracy: 0.7628 - val_loss: 2.5523\n",
      "Epoch 30/30\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9664 - loss: 0.2489 - val_accuracy: 0.7532 - val_loss: 2.6191\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5441 - loss: 4.3616\n",
      "Final loss: 2.619051933288574\n",
      "Final accuracy: 0.7532051205635071\n",
      "Final f1_score: 0.8336933045356372\n",
      "Final recall_score: 0.9897435897435898\n",
      "Final precision: 0.7201492537313433\n"
     ]
    }
   ],
   "source": [
    "class_weight = {0: 3.0, 1: 1.0} # As class 1 has more training data than class 2\n",
    "model = models.Sequential(\n",
    "[\n",
    "layers.Input(shape=(X_train.shape[1],X_train.shape[2],X_train.shape[3])),\n",
    "layers.Conv2D(4,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_1'),\n",
    "layers.MaxPool2D((2,2),name='max_pool_1'),\n",
    "layers.Conv2D(2,kernel_size=(3,3),strides=1,padding='same',activation='relu',name='conv_layer_2'),\n",
    "layers.MaxPool2D((2,2),name='max_pool_2'),\n",
    "layers.Flatten(),\n",
    "layers.Dense(8, activation='relu'),\n",
    "layers.Dense(4, activation='relu'),\n",
    "layers.Dropout(0.5), # To avoid overfitting\n",
    "layers.Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),loss='categorical_crossentropy' , metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=30,validation_data=(X_test,y_test),shuffle=True, class_weight=class_weight)\n",
    "p = model.predict(X_test)\n",
    "preds = np.argmax(np.round(p), axis=1)\n",
    "y_test_modified = np.argmax(y_test, axis=1)\n",
    "loss, accuracy = model.evaluate(x=X_test,y=y_test)\n",
    "print(f'Final loss: {loss}')\n",
    "print(f'Final accuracy: {accuracy}')\n",
    "print(f'Final f1_score: {f1_score(y_test_modified, preds)}')\n",
    "print(f'Final recall_score: {recall_score(y_test_modified, preds)}')\n",
    "print(f'Final precision: {precision_score(y_test_modified, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "886b7542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_modified, preds)\n",
    "cmd = ConfusionMatrixDisplay(cm)\n",
    "cmd.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0bf104b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_medical_image.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc11fdf",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb7399",
   "metadata": {},
   "source": [
    "## 1. Project Goals\n",
    "The primary goal of this project is to develop a machine learning model capable of analyzing medical images for disease detection. This involves:\n",
    "\n",
    "Performing Exploratory Data Analysis (EDA) to understand the dataset's characteristics.\n",
    "Preprocessing the dataset, including splitting into training and testing sets and normalizing pixel values.\n",
    "Developing a Convolutional Neural Network (CNN) using TensorFlow.\n",
    "Experimenting with different neural network architectures, and hyperparameters to optimize the model's performance.\n",
    "Evaluating the model's performance using metrics such as accuracy, precision, recall, and F1 score.\n",
    "Visualizing results to assess the model’s efficacy in diagnosing different medical conditions.\n",
    "\n",
    "## 2. Step-by-Step Approach\n",
    "#### Step 1: Data Exploration\n",
    "Download the Dataset: The dataset used in this project is a medical image dataset consisting of X-ray images, including images for 'NORMAL' and 'PNEUMONIA' cases. This dataset was downloaded and stored in the local directory.\n",
    "Familiarize with the Dataset: The dataset structure was explored to understand the distribution of classes ('NORMAL' and 'PNEUMONIA') and the image dimensions. This step helped ensure balanced class representation for model training.\n",
    "#### Step 2: Data Preprocessing\n",
    "Loading and Preprocessing Images:\n",
    "A function load_and_preprocess() was created to load images from specified directories, resize them to a uniform size (250x250), convert them from BGR to RGB, and normalize pixel values to the range [0, 1].\n",
    "Separate datasets for training and testing were created for each class ('NORMAL' and 'PNEUMONIA').\n",
    "Splitting the Dataset:\n",
    "The images were combined to form the full training and testing datasets.\n",
    "Corresponding labels were created (0 for 'NORMAL' and 1 for 'PNEUMONIA'), and one-hot encoding was applied to these labels using utils.to_categorical.\n",
    "#### Step 3: Model Building\n",
    "Selecting a Framework: TensorFlow and its Keras API were chosen for building the CNN model due to their flexibility and popularity in the machine learning community.\n",
    "Designing the CNN Architectures:\n",
    "Four different CNN architectures were tested to determine the best-performing structure:\n",
    "Structure 1: Two convolutional layers followed by two fully connected (dense) layers.\n",
    "Structure 2: One convolutional layer followed by two fully connected layers.\n",
    "Structure 3: Two convolutional layers followed by one fully connected layer.\n",
    "Structure 4: One convolutional layer followed by one fully connected layer.\n",
    "Compiling the Models: Each model was compiled using the Adam optimizer with a learning rate of 0.01, categorical cross-entropy as the loss function, and accuracy as the evaluation metric.\n",
    "Training and Evaluating the Models:\n",
    "Each model was trained on the dataset for 10 epochs with validation data. The performance was evaluated using accuracy scores.\n",
    "Structure 1 was identified as the best-performing model based on the evaluation.\n",
    "#### Step 4: Hyperparameter Tuning\n",
    "Optimizing the Number of Filters:\n",
    "The number of filters in the convolutional layers was experimented with values [32, 16, 8, 4].\n",
    "It was determined that using 4 filters provided the best performance.\n",
    "Optimizing the Number of Nodes:\n",
    "Different values for the number of nodes in dense layers were tested [32, 16, 8, 4].\n",
    "8 nodes were chosen as the optimal configuration to balance performance and training speed.\n",
    "Selecting the Best Learning Rate:\n",
    "Various learning rates [0.0001, 0.001, 0.01, 0.1] and finer variations [0.005, 0.007, 0.01, 0.03, 0.06] were tested.\n",
    "A learning rate of 0.01 consistently provided the best results.\n",
    "Determining the Optimal Batch Size:\n",
    "Different batch sizes [16, 32, 64, 128] were tested.\n",
    "The default batch size of 32 was found to be the most effective.\n",
    "Finding the Best Number of Epochs:\n",
    "Several values for the number of epochs [5, 10, 20, 30, 40, 50] were tested to determine the ideal training duration.\n",
    "Training for 30 epochs provided the best balance between training time and performance.\n",
    "#### Step 5: Final Model Training\n",
    "Training the Optimized Model:\n",
    "The model was retrained with the optimal hyperparameters: 4 filters, 8 nodes, learning rate of 0.01, batch size of 32, and 30 epochs.\n",
    "The model's performance was further validated using the test dataset.\n",
    "#### Step 6: Model Evaluation\n",
    "Performance Metrics:\n",
    "The model was evaluated using key metrics: accuracy, F1 score, precision, and recall.\n",
    "The evaluation metrics were printed, and the confusion matrix was used to visualize performance across different conditions.\n",
    "Analysis of Results:\n",
    "The final model showed significant efficacy in distinguishing between 'NORMAL' and 'PNEUMONIA' X-ray images, with optimal accuracy and balanced recall and precision.\n",
    "\n",
    "## 3. Results Analysis\n",
    "Model Performance:\n",
    "The best-performing model demonstrated high accuracy and robust performance across different metrics. The evaluation results were as follows:\n",
    "##### Accuracy: Measures the percentage of correct predictions.\n",
    "##### F1 Score: The harmonic mean of precision and recall, indicating the balance between them.\n",
    "##### Precision: Represents the proportion of true positive results among all positive results predicted by the model.\n",
    "##### Recall: Indicates the proportion of true positive results among all actual positive samples.\n",
    "\n",
    "## 4. Conclusion\n",
    "The project successfully developed a CNN model for medical image analysis, capable of detecting diseases from X-ray images with high accuracy. By systematically exploring and optimizing various network architectures, hyperparameters, and training strategies, the project achieved a balance between accuracy and computational efficiency. The model’s performance demonstrated the potential of deep learning techniques in medical diagnostics, with future enhancements focusing on more complex datasets and diverse medical conditions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
